from ai_tools.text2text import *
from ai_tools.text2image import *
import chardet
def try_decode(file_data, encodings):
    for encoding in encodings:
        try:
            return file_data.decode(encoding)
        except UnicodeDecodeError:
            continue
    return None


# openai_client=OpenAI(api_key=st.secrets['OPENAI_API_KEY'],base_url=st.secrets['BASE_URL'])
# MODEL_NAME = st.secrets["MODEL_NAME"]
openai_client=OpenAI(api_key=st.secrets['DEEPSEEK_API_KEY'],base_url=st.secrets['DEEPSEEK_BASE_URL'])
MODEL_NAME = st.secrets["DEEPSEEK_MODEL_NAME"]

st.set_page_config(page_title="å¼€å§‹ç¿»è¯‘ä½ çš„å°è¯´", page_icon="ğŸ¤")
st.sidebar.header("ğŸ¤Story_Translate")

st.header("ç¬¬ä¸€æ­¥: å°è¯´è§£æ",divider=True)
# ä¸Šä¼ å°è¯´æ–‡æœ¬
uploaded_file=st.file_uploader('ä¸Šä¼ å°è¯´æ–‡æœ¬',type=["txt"])
text=""
lines=[]
if uploaded_file is not None:
    # è¯»å–æ–‡ä»¶å†…å®¹
    raw_data = uploaded_file.read()
    result = chardet.detect(raw_data)
    detected_encoding = result['encoding']
    st.write("file encoding:", detected_encoding)
    # å°è¯•ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç è§£ç 
    if detected_encoding is not None:
        if detected_encoding not in ['gb2312','GB2312']:
            text = raw_data.decode(detected_encoding)
        else:
            text = raw_data.decode('gbk')
        lines = text.splitlines()
        st.write("line num:", len(lines))
    else:
        # å¦‚æœæ£€æµ‹åˆ°çš„ç¼–ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–å¸¸è§ç¼–ç 
        encodings = ['utf-8', 'gbk', 'latin1', 'iso-8859-1']
        text = try_decode(raw_data, encodings)

        if text is not None:
            lines = text.splitlines()
            st.write("line num:", len(lines))
        else:
            st.error("æ— æ³•è§£ç æ–‡ä»¶å†…å®¹ï¼Œè¯·ç¡®è®¤æ–‡ä»¶ç¼–ç ã€‚")

    st.write("line num:", len(lines))

    # åˆ›å»ºä¸€ä¸ªæ»šåŠ¨æ–‡æœ¬æ¡†æ¥å±•ç¤ºå†…å®¹
    st.text_area("å°è¯´å†…å®¹", value=text, height=500)  # å¯ä»¥è°ƒæ•´é«˜åº¦

    # å±•ç¤ºå°è¯´æŒ‰ç…§ç« èŠ‚ç»“æ„åŒ–çš„jsonæ ¼å¼
    structure_res=structure_story(lines)
    st.json(structure_res)
    st.session_state['structure_res']=structure_res
else:
    st.info("è¯·åœ¨ä¸Šä¼ ä¸€ä¸ª.txtæ ¼å¼çš„å°è¯´æ–‡æœ¬ã€‚")

parse_stroy_fake=st.radio("fake_parse",["not fake","fake"],horizontal=True)

target_language=st.radio("ç›®æ ‡è¯­è¨€",["è‹±è¯­","æ³•è¯­","æ—¥è¯­","éŸ©è¯­","ä¿„è¯­","è¥¿ç­ç‰™è¯­"],index=0,horizontal=True)
model=st.radio("æ¨¡å‹å",["o3-mini-2025-01-31","deepseek-chat"],index=0,horizontal=True)
if 'deepseek' in model.lower():
    openai_client=OpenAI(api_key=st.secrets['DEEPSEEK_API_KEY'],base_url=st.secrets['DEEPSEEK_BASE_URL'])
    MODEL_NAME = st.secrets["DEEPSEEK_MODEL_NAME"]
else:
    openai_client=OpenAI(api_key=st.secrets['OPENAI_API_KEY'],base_url=st.secrets['BASE_URL'])
    MODEL_NAME = st.secrets["MODEL_NAME"]
if st.button(label="ç¿»è¯‘"):
    if st.session_state.get('structure_res') is not None:
        is_fake=parse_stroy_fake=="fake"
        # åˆ†ç« èŠ‚ç¿»è¯‘
        structure_res=st.session_state['structure_res']
        translate_res={}
        # æ˜¾ç¤ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        for i,chapter_name in enumerate(structure_res.keys()):
            chapter_content=structure_res[chapter_name]
            res=translate_story(story=chapter_content,target_language=target_language,client=openai_client,model_name=MODEL_NAME,fake=is_fake)
            translate_res[chapter_name]={
                'åŸå§‹å†…å®¹':chapter_content,
                'ç¿»è¯‘ç»“æœ':res,
            }
            progress_bar.progress((i + 1) / len(structure_res))
        st.session_state['translate_res']=translate_res
        st.json(translate_res)
    else:
        st.info("è¯·ä¸Šä¼ å°è¯´")


